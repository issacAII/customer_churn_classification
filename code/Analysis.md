##Experiment 1 
5 ML classifiers and 1 dummy classifier are compared. These classifiers are very common in machine learning experiment and each of them have their strength and weakness respectively. However, based on no free lunch theorem, no single machine learning algorithm is universally the best-performing algorithm for all problems. In this dataset, it is concluded that Decision Tree achieve the best performance in customer churn classification. The optimum split in this classifier is chosen by the features with less Gini Index. The maximum depth of tree and leaf node relatively low to prevent overfitting. Besides, the graphical decision tree is printed out. We can observe that the age, whether is active member and number of products are mostly used to compute the tree rules. This is reasonable because older customer may not be likely to leave if he does utilise many products in this bank. By using these strategic rules, Decision Tree model can perform the classification efficiently in this dataset. 
##Experiment 2
After generating the decision tree rules for both models using Filter Subset 4 and Wrapper Subset, it is observed that the decision trees are identical to the one obtained using full dataset.  In the two subsets, there are Age, NumOfProducts, and IsActiveMember. This implies that for the models using decision tree, the three above mentioned features are the three most important predictors of customer churn. Since decision tree models using subsets with six features generalized equally well as the model using full subset, it can be safely concluded that the models with small number of features are better in this case, as the dimensionality has dropped by four.
##Experiment 3 
Bagging build multiple Decision Tree models based on different samples of training data. It is same goes to Boosting method which build multiple Decision Tree models by reweighing the training instances. Although the classification result seems being improved, it still cannot conclude that using these two methods can improve the predictive power of the model. It is possible that the results from all models are averaged and hence achieves a slightly higher performance (0.85) compared to single Decision Tree model (0.84) from Experiment 1. As for Voting and Stacking methods which achieve lower performance, it is suspected that majority of the votes for the wrong class, reducing the overall accuracy of the ensemble. Besides, they are likely to make the same types of errors because all the classifiers are trained on the same data.
##Experiment 4
The changes to the best performing models’ performance metric scores are minute, with only 1%-2% differences between each iteration. Based on what we learn and know, too little training data might result in a poor approximation and might experience underfitting whereas too much training data might overfit the model, where both scenarios would result in poor model performance. As there are not many differences between the F1-Scores of each best performing model when the training sample size is changed in increments of 10%, I would prefer choosing a balanced training sample size where the model would be less likely to underfit and overfit the training data. For Set 1 and Set 2, 70% training data size would consider as the sweet spot for an optimal balance between training data size and performance . As for Set 3, an 80% training sample size could be ideal to produce an optimal model based on the selected performance metric.
##Across all four experiment sets 
Observed that the Decision Tree model achieves quite stable classification performance in this dataset. It is choosing some specific features (Age, NumOfProducts, and IsActiveMember) for generating its own decision rules to predict whether the customer churn or not. And this explained when we try to reduce the features in Experiment 2, as long as those specific features are contained, the F1 score will not decrease. This is also proved by Experiment 4, which getting similar results for set 1 and set 2. Ensemble learning on decision tree in this case doesn’t improve much of the result. Moreover, changing the size of training dataset doesn’t change the decision rules and hence not much effect observed. In conclusion, the best model chosen for this project is Decision Tree model (criterion= 'gini', max_depth= 5, max_leaf_nodes= 9, min_samples_leaf= 1), with the subset of “CreditScore”, “Balance”, “Geography”, “IsActiveMember”, “Age”, “NumOfProducts”, and 70% training data size. This is because of using full feature is having similar performance when reduce to only 6 features. 
